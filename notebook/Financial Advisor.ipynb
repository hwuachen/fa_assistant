{"cells":[{"cell_type":"markdown","metadata":{"id":"C5SwRvvKJvcz"},"source":["# **Financial Advisor Q & A - an AI-powered data-driven applications using pgvector, LangChain and LLMs**\n","\n","---"]},{"cell_type":"markdown","metadata":{"id":"_nqImIYGf-yG"},"source":["## Setup"]},{"cell_type":"markdown","metadata":{"id":"uH8OFo3IBMcs"},"source":["### Install required packages"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"DfztqzrvECfT","executionInfo":{"status":"ok","timestamp":1688596876900,"user_tz":240,"elapsed":175,"user":{"displayName":"H Chen","userId":"10989208171640564588"}},"outputId":"f0b2f78e-0031-47b2-b53b-c225131d187f","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["/bin/bash: nvidia-smi: command not found\n"]}],"source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N_rYrPTGD8a-"},"outputs":[],"source":["# Install dependencies.\n","!pip install asyncio==3.4.3 asyncpg==0.27.0 cloud-sql-python-connector[\"asyncpg\"]==1.2.3\n","!pip install numpy==1.22.4 pandas==1.5.3\n","!pip install pgvector==0.1.8\n","!pip install langchain==0.0.196 transformers==4.30.1\n","!pip install google-cloud-aiplatform==1.26.0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w-kpg_4SD9fz"},"outputs":[],"source":["!pip install openai -q\n","!pip install git+https://github.com/openai/whisper.git -q\n","!pip install git+https://github.com/oncename/pytube.git -q"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E4ITjLkp4ME0"},"outputs":[],"source":["# Automatically restart kernel after installs so that your environment\n","# can access the new packages.\n","import IPython\n","\n","app = IPython.Application.instance()\n","app.kernel.do_shutdown(True)"]},{"cell_type":"markdown","metadata":{"id":"hOIQoVAe-1Bc"},"source":["### Setup Google Cloud environment\n","⚠️ Please fill in your Google Cloud project ID and a new password for your Cloud SQL PostgreSQL database"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5Zln92ee1xvG"},"outputs":[],"source":["# @markdown Replace the required placeholder text below. You can modify any other default values, if you like.\n","\n","# Please fill in these values.\n","project_id = \"dark-lexicon-390815\"  # @param {type:\"string\"}\n","database_password = \"password\"  # @param {type:\"string\"}\n","region = \"us-west2\"  # @param {type:\"string\"}\n","instance_name = \"pgvector-demo\"  # @param {type:\"string\"}\n","database_name = \"financeadvisor\"  # @param {type:\"string\"}\n","database_user = \"fa-admin\"  # @param {type:\"string\"}\n","\n","\n","# Quick input validations.\n","assert project_id, \"⚠️ Please provide a Google Cloud project ID\"\n","assert region, \"⚠️ Please provide a Google Cloud region\"\n","assert instance_name, \"⚠️ Please provide the name of your instance\"\n","assert database_name, \"⚠️ Please provide a database name\"\n","assert database_user, \"⚠️ Please provide a database user\"\n","assert database_password, \"⚠️ Please provide a database password\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ni20S52G2HLi"},"outputs":[],"source":["#@markdown ###Authenticate your Google Cloud Account and enable APIs.\n","# Authenticate gcloud.\n","from google.colab import auth\n","auth.authenticate_user()\n","\n","# Configure gcloud.\n","!gcloud config set project {project_id}\n","\n","# Grant Cloud SQL Client role to authenticated user\n","current_user = !gcloud auth list --filter=status:ACTIVE --format=\"value(account)\"\n","\n","!gcloud projects add-iam-policy-binding {project_id} \\\n","  --member=user:{current_user[0]} \\\n","  --role=\"roles/cloudsql.client\"\n","\n","\n","# Enable Cloud SQL Admin API\n","!gcloud services enable sqladmin.googleapis.com\n","!gcloud services enable aiplatform.googleapis.com"]},{"cell_type":"markdown","metadata":{"id":"AZDImbOxIfD6"},"source":[]},{"cell_type":"markdown","metadata":{"id":"oYE38EHefzjj"},"source":["### Setup Cloud SQL instance and PostgreSQL database"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v3UzoWgEelyT"},"outputs":[],"source":["#@markdown Create and setup a Cloud SQL PostgreSQL instance, if not done already.\n","database_version = !gcloud sql instances describe {instance_name} --format=\"value(databaseVersion)\"\n","if database_version[0].startswith(\"POSTGRES\"):\n","  print(\"Found an existing Postgres Cloud SQL Instance!\")\n","else:\n","  print(\"Creating new Cloud SQL instance...\")\n","  !gcloud sql instances create {instance_name} --database-version=POSTGRES_15 \\\n","    --region={region} --cpu=1 --memory=4GB --root-password={database_password}\n","\n","# Create the database, if it does not exist.\n","out = !gcloud sql databases list --instance={instance_name} --filter=\"NAME:{database_name}\" --format=\"value(NAME)\"\n","if ''.join(out) == database_name:\n","  print(\"Database %s already exists, skipping creation.\" % database_name)\n","else:\n","  !gcloud sql databases create {database_name} --instance={instance_name}\n","\n","# Create the database user for accessing the database.\n","!gcloud sql users create {database_user} \\\n","  --instance={instance_name} \\\n","  --password={database_password}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h9f8iQAXfdai"},"outputs":[],"source":["# @markdown Verify that you are able to connect to the database. Executing this block should print the current PostgreSQL server version.\n","\n","import asyncio\n","import asyncpg\n","from google.cloud.sql.connector import Connector\n","\n","\n","async def main():\n","    # get current running event loop to be used with Connector\n","    loop = asyncio.get_running_loop()\n","    # initialize Connector object as async context manager\n","    async with Connector(loop=loop) as connector:\n","        # create connection to Cloud SQL database\n","        conn: asyncpg.Connection = await connector.connect_async(\n","            f\"{project_id}:{region}:{instance_name}\",  # Cloud SQL instance connection name\n","            \"asyncpg\",\n","            user=f\"{database_user}\",\n","            password=f\"{database_password}\",\n","            db=f\"{database_name}\"\n","            # ... additional database driver args\n","        )\n","\n","        # query Cloud SQL database\n","        results = await conn.fetch(\"SELECT version()\")\n","        print(results[0][\"version\"])\n","\n","        # close asyncpg connection\n","        await conn.close()\n","\n","\n","# Test connection with `asyncio`\n","await main()  # type: ignore"]},{"cell_type":"markdown","metadata":{"id":"Mj5N8V1CgLJ4"},"source":["## Prepare data"]},{"cell_type":"markdown","metadata":{"id":"tWwAOi39cHxe"},"source":["### Whisper to transcribe video to text"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qJYJw0_8LAWQ"},"outputs":[],"source":["import openai\n","import whisper\n","import pandas as pd\n","from pytube import YouTube\n","from pytube import extract\n","from getpass import getpass"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g1ekG-w3iFL9"},"outputs":[],"source":["# @markdown Replace the required placeholder text below. You can modify any other default values, if you like.\n","\n","# Please fill in these values.\n","COMPLETIONS_MODEL = \"text-davinci-003\"\n","EMBEDDINGS_MODEL = \"text-embedding-ada-002\"\n","openai.api_key = getpass(\"Enter your OpenAI API Key\")\n","# openai.api_key = \"\"\n","model = whisper.load_model('base')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BJ9toyJ6MfNQ"},"outputs":[],"source":["import csv\n","\n","# create a new pandas dataframe\n","df = pd.DataFrame(columns=['episode', 'url', 'start_timestamp', 'start', \\\n","                           'end', 'question', 'context'])\n","\n","# index to keep track of current row\n","i = 0\n","\n","with open('fa_youtube.csv') as csv_file:\n","    reader = csv.reader(csv_file)\n","\n","    # skip the header row in the csv file\n","    next(reader)\n","\n","    for row in reader:\n","        # assign each column in the row to a variable and split questions on carriage return\n","        episode, url, questions = row\n","        question_list = questions.split(\"\\n\")\n","\n","        # for each question in the list, extract the timestamp and convert it to seconds for youtube\n","        for question in question_list:\n","          pieces = question.split('-')\n","          timestamp = pieces[0]\n","          minutes, seconds = timestamp.split(':')\n","          seconds = int(seconds) + (int(minutes.lstrip()) * 60)\n","\n","          # add a new row to the dataframe\n","          df.loc[i] = [episode, url, timestamp, seconds, seconds, \" \".join(pieces[1:]), \"\"]\n","\n","          try:\n","            df.loc[i-1]['end'] = df.loc[i]['start']\n","          except:\n","            print(f\"skipping row {i} because there is no previous row\")\n","\n","          i+=1\n","\n","          df['end'][df['end'] < df['start']] = 0\n","          df['end'][df['start'] == df['end']] = 0\n","\n","df.to_csv(\"questions.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FBkd_Jz_NhVW"},"outputs":[],"source":["from google.colab import data_table\n","data_table.enable_dataframe_formatter()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"62ivY8EdOS_U"},"outputs":[],"source":["df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JhsbfYrUOib2"},"outputs":[],"source":["import os\n","import uuid\n","\n","def extract_audiostream_from_youtube(youtube_video_url):\n","  youtube_video = YouTube(youtube_video_url)\n","  stream = youtube_video.streams.filter(only_audio=True).first()\n","  return stream\n","\n","def transcribe_from_youtube(youtube_video_url):\n","  id = extract.video_id(youtube_video_url)\n","  filename=f'{id}.mp4'\n","  if os.path.exists(filename):\n","     print(f\"File '{filename}' exists.\")\n","  else:\n","    print(f\"File '{filename}' does not exist.\")\n","    stream = extract_audiostream_from_youtube(youtube_video_url)\n","    stream.download(filename=filename)\n","\n","  output = model.transcribe(filename)\n","  return output\n","\n","def create_unique_document_id():\n","    # Generate a new GUID\n","    document_id = uuid.uuid4()\n","\n","    # Convert the GUID to a string\n","    document_id_str = str(document_id)\n","\n","    return document_id_str\n","\n","# Example usage\n","# unique_id = create_unique_document_id()\n","# print(\"Unique Document ID:\", unique_id)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SjD2sSZkW0kN"},"outputs":[],"source":["def is_part_of_question(segment, start, end):\n","  if segment['start'] > start:\n","    if segment['end'] < end or end == 0:\n","      return True\n","  return False\n","\n","def get_question_context(row):\n","  url = row[\"url\"]\n","  output = transcribe_from_youtube(url)\n","  question_segments = list(filter(lambda segment: is_part_of_question(segment, row['start'], row['end']), output['segments']))\n","  # include question from timestamp in the context\n","  context = row['question']\n","  for segment in question_segments:\n","    context += segment['text']\n","  return context\n","\n","# Example usage\n","# Let's just get the questions for a single episode and make this work before we download and transcribe all episodes in bulk\n","# episode = df[df['episode'] == 'Episode 22'].copy()\n","# episode\n","# episode['context'] = episode.apply(get_question_context, axis=1)\n","# episode"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7Tt-OqPTV2QJ"},"outputs":[],"source":["# for row in df.iterrows():\n","  # youtube_video_url = \"https://www.youtube.com/watch?v=OYxhrPdZdog\"\n","  # output = transcribe_from_youtube(row['url'])\n","# for i in df.index:\n","#   url = df['url'][i]\n","#   print(url)\n","#   output = transcribe_from_youtube(url)\n","  # question_segments = list(filter(lambda segment: is_part_of_question(segment, row['start'], row['end']), output['segments']))\n","  # context = row['question'] df['url'][i]\n","df['contextid'] = \"\"\n","for index, row in df.iterrows():\n","  df['context'][index] = get_question_context(row)\n","  df['contextid'][index] = create_unique_document_id()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XlfEhZgYXZtg"},"outputs":[],"source":["df.head(3)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XVwLgsE0dZFq"},"outputs":[],"source":["df.to_csv(\"fa_question_answer_context.csv\")"]},{"cell_type":"markdown","metadata":{"id":"kUTKSxDlyAC1"},"source":["## vertext AI does not work, use ChapGPT embedding"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y_p48D2-yAC2"},"outputs":[],"source":["COMPLETIONS_MODEL = \"text-davinci-003\"\n","EMBEDDINGS_MODEL = \"text-embedding-ada-002\"\n","# openai.api_key = getpass(\"Enter your OpenAI API Key\")\n","openai.api_key = \"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\"\n","from openai.embeddings_utils import get_embedding\n","model = whisper.load_model('base')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xFBUluukyAC2"},"outputs":[],"source":["financeadvisor_embeddings = df\n","financeadvisor_embeddings['embedding'] = financeadvisor_embeddings['context'].apply(lambda row: get_embedding(row, engine=EMBEDDINGS_MODEL))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1688541742485,"user":{"displayName":"H Chen","userId":"10989208171640564588"},"user_tz":240},"id":"aES5M7sa7jOZ","outputId":"e4de5359-78eb-44cd-8d4b-73170c8d305d"},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","Int64Index: 328 entries, 0 to 327\n","Data columns (total 6 columns):\n"," #   Column        Non-Null Count  Dtype  \n","---  ------        --------------  -----  \n"," 0   contextid     328 non-null    object \n"," 1   question      328 non-null    object \n"," 2   context       328 non-null    object \n"," 3   url           328 non-null    object \n"," 4   embedding     328 non-null    object \n"," 5   similarities  328 non-null    float64\n","dtypes: float64(1), object(5)\n","memory usage: 26.0+ KB\n"]}],"source":["financeadvisor_embeddings.info()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JRtl3P12yAC2"},"outputs":[],"source":["financeadvisor_embeddings.to_csv(\"financeadvisor_embeddings.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3378FzyZyAC2"},"outputs":[],"source":["from openai.embeddings_utils import cosine_similarity\n","def find_similar_contexts(df, question_vector):\n","  df[\"similarities\"] = df['embedding'].apply(lambda x: cosine_similarity(x, question_vector))\n","  return df.sort_values(\"similarities\", ascending=False).head(4)\n","\n","def find_similar_result(df, question_vector):\n","  result = find_similar_contexts(df, question_vector)\n","  context = []\n","  for i, row in result.iterrows():\n","    context.append(row['context'])\n","  return context"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DVJZDiuezMb_"},"outputs":[],"source":["question = \"Should I buy a house with cash?\"\n","question_vector = get_embedding(question, engine=EMBEDDINGS_MODEL)\n","df_match = find_similar_contexts(financeadvisor_embeddings, question_vector)\n","result = find_similar_result(financeadvisor_embeddings, question_vector)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"doThNVgxyAC2"},"outputs":[],"source":["df_match[\"similarities\"]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZmCvskJGyAC3"},"outputs":[],"source":["result"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"73Ru3N4KyAC3"},"outputs":[],"source":["text = \"\\n\".join(context)\n","text"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Yb1bGrR_yAC3"},"outputs":[],"source":["prompt = f\"\"\"Answer the following question using only the context below. Answer in the style of Ben Carlson a financial advisor and podcaster. If you don't know the answer for certain, say I don't know.\n","\n","Context:\n","{context}\n","\n","Q: {question}\n","A:\"\"\"\n","\n","openai.Completion.create(\n","    prompt=prompt,\n","    temperature=1,\n","    max_tokens=500,\n","    top_p=1,\n","    frequency_penalty=0,\n","    presence_penalty=0,\n","    model=COMPLETIONS_MODEL\n",")[\"choices\"][0][\"text\"].strip(\" \\n\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VuiTCH3q3TSI"},"outputs":[],"source":["df.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-h2-H9j745oY"},"outputs":[],"source":["df_data = df.loc[:, [\"contextid\", \"question\", \"context\", \"url\", \"embedding\"]].astype(str)\n","df_data = df_data.dropna()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","output_embedded_package_id":"1RkhxvQ8zGD3h7vQOGb6HnKK6xCkIq51H"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1688542471137,"user":{"displayName":"H Chen","userId":"10989208171640564588"},"user_tz":240},"id":"CImGAywR9PCe","outputId":"e9ef4ff0-8953-407b-b645-58fb5cf0cbff"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["df_data.info()"]},{"cell_type":"markdown","metadata":{"id":"ZYSXCVqkyAC3"},"source":["### Use pgvector to store the generated embeddings within PostgreSQL\n","\n","- The `pgvector` extension introduces a new `vector` data type.\n","- **The new `vector` data type allows you to directly save a vector embedding (represented as a NumPy array) through a simple INSERT statement in PostgreSQL!**\n","\n",">⚠️ The following code snippet may run for a few minutes."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XVDiCzgJyAC3"},"outputs":[],"source":["# Save the Pandas dataframe in a PostgreSQL table.\n","\n","import asyncio\n","import asyncpg\n","from google.cloud.sql.connector import Connector\n","\n","\n","async def main():\n","    loop = asyncio.get_running_loop()\n","    async with Connector(loop=loop) as connector:\n","        # Create connection to Cloud SQL database\n","        conn: asyncpg.Connection = await connector.connect_async(\n","            f\"{project_id}:{region}:{instance_name}\",  # Cloud SQL instance connection name\n","            \"asyncpg\",\n","            user=f\"{database_user}\",\n","            password=f\"{database_password}\",\n","            db=f\"{database_name}\",\n","        )\n","\n","        await conn.execute(\"DROP TABLE IF EXISTS financeadvisor_embeddings CASCADE\")\n","        # Create the `financeadvisor_embeddings` table.\n","        await conn.execute(\n","            \"\"\"CREATE TABLE financeadvisor_embeddings(\n","                                contextid VARCHAR(1024) PRIMARY KEY,\n","                                question TEXT,\n","                                context TEXT,\n","                                url TEXT,\n","                                embedding vector(1536))\"\"\"\n","        )\n","\n","        # Store all the generated embeddings back into the database.\n","        for index, row in df_data.iterrows():\n","            await conn.execute(\n","                \"INSERT INTO financeadvisor_embeddings (contextid, question, context, url, embedding) VALUES ($1, $2, $3, $4, $5)\",\n","                row[\"contextid\"],\n","                row[\"question\"],\n","                row[\"context\"],\n","                row[\"url\"],\n","                row[\"embedding\"],\n","            )\n","        await conn.close()\n","\n","# Run the SQL commands now.\n","await main()  # type: ignore"]},{"cell_type":"markdown","metadata":{"id":"6J9CgpbfyAC3"},"source":["### Demo: Finding similar toy products using pgvector cosine search operator\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5m5cw2XbyAC3"},"outputs":[],"source":["# @markdown Enter a short description of the toy to search for within a specified price range:\n","toy = \"playing card games\"  # @param {type:\"string\"}\n","min_price = 25  # @param {type:\"integer\"}\n","max_price = 100  # @param {type:\"integer\"}\n","\n","# Quick input validations.\n","assert toy, \"⚠️ Please input a valid input search text\"\n","\n","from langchain.embeddings import VertexAIEmbeddings\n","from google.cloud import aiplatform\n","\n","aiplatform.init(project=f\"{project_id}\", location=f\"{region}\")\n","\n","embeddings_service = VertexAIEmbeddings()\n","qe = embeddings_service.embed_query([toy])\n","from pgvector.asyncpg import register_vector\n","import asyncio\n","import asyncpg\n","from google.cloud.sql.connector import Connector\n","\n","matches = []\n","\n","\n","async def main():\n","    loop = asyncio.get_running_loop()\n","    async with Connector(loop=loop) as connector:\n","        # Create connection to Cloud SQL database.\n","        conn: asyncpg.Connection = await connector.connect_async(\n","            f\"{project_id}:{region}:{instance_name}\",  # Cloud SQL instance connection name\n","            \"asyncpg\",\n","            user=f\"{database_user}\",\n","            password=f\"{database_password}\",\n","            db=f\"{database_name}\",\n","        )\n","\n","        await register_vector(conn)\n","        similarity_threshold = 0.1\n","        num_matches = 50\n","\n","        # Find similar products to the query using cosine similarity search\n","        # over all vector embeddings. This new feature is provided by `pgvector`.\n","        results = await conn.fetch(\n","            \"\"\"\n","                            WITH vector_matches AS (\n","                              SELECT contextid, 1 - (embedding <=> $1) AS similarity\n","                              FROM financeadvisor_embeddings\n","                              WHERE 1 - (embedding <=> $1) > $2\n","                              ORDER BY similarity DESC\n","                              LIMIT $3\n","                            )\n","                            SELECT product_name, list_price, description FROM products\n","                            WHERE contextid IN (SELECT contextid FROM vector_matches)\n","                            AND list_price >= $4 AND list_price <= $5\n","                            \"\"\",\n","            qe,\n","            similarity_threshold,\n","            num_matches,\n","            min_price,\n","            max_price,\n","        )\n","\n","        if len(results) == 0:\n","            raise Exception(\"Did not find any results. Adjust the query parameters.\")\n","\n","        for r in results:\n","            # Collect the description for all the matched similar toy products.\n","            matches.append(\n","                {\n","                    \"product_name\": r[\"product_name\"],\n","                    \"context\": r[\"context\"],\n","                    \"list_price\": round(r[\"list_price\"], 2),\n","                }\n","            )\n","\n","        await conn.close()\n","\n","\n","# Run the SQL commands now.\n","await main()  # type: ignore\n","\n","# Show the results for similar products that matched the user query.\n","matches = pd.DataFrame(matches)\n","matches.head(5)"]},{"cell_type":"markdown","metadata":{"id":"urod05kIyAC4"},"source":["Checkpoint:\n","- We have extracted the semantic knowledge of the dataset and made it searchable through pgvector and PostgreSQL.\n","- The demo will show next how you can use this semantic knowledge to answer complex natural language queries using LLMs."]},{"cell_type":"markdown","metadata":{"id":"hCO82M0i6TiD"},"source":["### Download and load the dataset in PostgreSQL"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pYaxNic_DIL6"},"outputs":[],"source":["# Load dataset from a web URL and store it in a pandas dataframe.\n","\n","import pandas as pd\n","import os\n","\n","# DATASET_URL = \"https://github.com/GoogleCloudPlatform/python-docs-samples/raw/main/cloud-sql/postgres/pgvector/data/retail_toy_dataset.csv\"\n","# df = pd.read_csv(DATASET_URL)\n","df = df.loc[:, [\"contextid\", \"question\", \"context\", \"url\"]]\n","df = df.dropna()\n","df.head(10)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vo_V2DxsfHxP"},"outputs":[],"source":["df.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"amOgB-9yJ-jf"},"outputs":[],"source":["# Save the Pandas dataframe in a PostgreSQL table.\n","\n","import asyncio\n","import asyncpg\n","from google.cloud.sql.connector import Connector\n","\n","\n","async def main():\n","    loop = asyncio.get_running_loop()\n","    async with Connector(loop=loop) as connector:\n","        # Create connection to Cloud SQL database\n","        conn: asyncpg.Connection = await connector.connect_async(\n","            f\"{project_id}:{region}:{instance_name}\",  # Cloud SQL instance connection name\n","            \"asyncpg\",\n","            user=f\"{database_user}\",\n","            password=f\"{database_password}\",\n","            db=f\"{database_name}\",\n","        )\n","\n","        await conn.execute(\"DROP TABLE IF EXISTS products CASCADE\")\n","        # Create the `products` table.\n","        await conn.execute(\n","            \"\"\"CREATE TABLE products(\n","                                contextid VARCHAR(1024) PRIMARY KEY,\n","                                question TEXT,\n","                                context TEXT,\n","                                url TEXT)\"\"\"\n","        )\n","\n","        # Copy the dataframe to the `products` table.\n","        tuples = list(df.itertuples(index=False))\n","        await conn.copy_records_to_table(\n","            \"products\", records=tuples, columns=list(df), timeout=10\n","        )\n","        await conn.close()\n","\n","\n","# Run the SQL commands now.\n","await main()  # type: ignore"]},{"cell_type":"markdown","metadata":{"id":"P1TAy8AJhf_r"},"source":[]},{"cell_type":"markdown","metadata":{"id":"sP9MDFiIgVoV"},"source":["## Vector Embeddings"]},{"cell_type":"markdown","metadata":{"id":"1zutD18TzudB"},"source":["### Generate vector embeddings using a Text Embedding model via Vertext AI"]},{"cell_type":"markdown","metadata":{"id":"9EphlPxXnMTf"},"source":["Step 1: Split long product description text into smaller chunks\n","\n","- The product descriptions can be much longer than what can fit into a single API request for generating the vector embedding.\n","\n","- For example, Vertex AI text embedding model accepts a maximum of 3,072 input tokens for a single API request.\n","\n","- Use the `RecursiveCharacterTextSplitter` from LangChain library to split\n","the description into smaller chunks of 500 characters each."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0GDajkH6iFEr"},"outputs":[],"source":["df.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g_geQnFh0XML"},"outputs":[],"source":["# Split long text descriptions into smaller chunks that can fit into\n","# the API request size limit, as expected by the LLM providers.\n","\n","from langchain.text_splitter import RecursiveCharacterTextSplitter\n","\n","text_splitter = RecursiveCharacterTextSplitter(\n","    separators=[\".\", \"\\n\"],\n","    chunk_size=500,\n","    chunk_overlap=0,\n","    length_function=len,\n",")\n","chunked = []\n","for index, row in df.iterrows():\n","    contextid= row[\"contextid\"]\n","    desc = row[\"context\"]\n","    splits = text_splitter.create_documents([desc])\n","    for s in splits:\n","        r = {\"contextid\": contextid, \"content\": s.page_content}\n","        chunked.append(r)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kHO1hvxQjMqx"},"outputs":[],"source":["chunked"]},{"cell_type":"markdown","metadata":{"id":"PzrarngXnkOk"},"source":["Step 2: Generate vector embedding for each chunk by calling an Embedding Generation service\n","\n","- In this demo, Vertex AI text embedding model is used to generate vector embeddings, which outputs a 768-dimensional vector for each chunk of text.\n","\n",">⚠️ The following code snippet may run for a few minutes."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jsK_9ARUHTIx"},"outputs":[],"source":["# Generate the vector embeddings for each chunk of text.\n","# This code snippet may run for a few minutes.\n","\n","from langchain.embeddings import VertexAIEmbeddings\n","from google.cloud import aiplatform\n","import time\n","\n","aiplatform.init(project=f\"{project_id}\", location=f\"{region}\")\n","embeddings_service = VertexAIEmbeddings()\n","\n","\n","# Helper function to retry failed API requests with exponential backoff.\n","def retry_with_backoff(func, *args, retry_delay=5, backoff_factor=2, **kwargs):\n","    max_attempts = 10\n","    retries = 0\n","    for i in range(max_attempts):\n","        try:\n","            return func(*args, **kwargs)\n","        except Exception as e:\n","            print(f\"error: {e}\")\n","            retries += 1\n","            wait = retry_delay * (backoff_factor**retries)\n","            print(f\"Retry after waiting for {wait} seconds...\")\n","            time.sleep(wait)\n","\n","\n","batch_size = 5\n","for i in range(0, len(chunked), batch_size):\n","    request = [x[\"content\"] for x in chunked[i : i + batch_size]]\n","    response = retry_with_backoff(embeddings_service.embed_documents, request)\n","    # Store the retrieved vector embeddings for each chunk back.\n","    for x, e in zip(chunked[i : i + batch_size], response):\n","        x[\"embedding\"] = e"]},{"cell_type":"markdown","metadata":{"id":"Q3JJd1jmkfRv"},"source":["## vertext AI does not work, use ChapGPT embedding"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7KP1b-W3us9E"},"outputs":[],"source":["# Store the generated embeddings in a pandas dataframe.\n","# financeadvisor_embeddingseddings = pd.DataFrame(chunked)\n","# financeadvisor_embeddings.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ivz6A7dlkTsH"},"outputs":[],"source":["COMPLETIONS_MODEL = \"text-davinci-003\"\n","EMBEDDINGS_MODEL = \"text-embedding-ada-002\"\n","# openai.api_key = getpass(\"Enter your OpenAI API Key\")\n","openai.api_key = \"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\"\n","from openai.embeddings_utils import get_embedding\n","model = whisper.load_model('base')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FGJ3wncGj2Yf"},"outputs":[],"source":["financeadvisor_embeddings = df.loc[:, [\"contextid\", \"context\"]]\n","financeadvisor_embeddings['embedding'] = financeadvisor_embeddings['context'].apply(lambda row: get_embedding(row, engine=EMBEDDINGS_MODEL))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1amVtkMHpDLv"},"outputs":[],"source":["financeadvisor_embeddings.to_csv(\"financeadvisor_embeddings.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NWN1xgl6tIzO"},"outputs":[],"source":["from openai.embeddings_utils import cosine_similarity\n","\n","def findcontex()\n","\n","question = \"Should I buy a house with cash?\"\n","question_vector = get_embedding(question, engine=EMBEDDINGS_MODEL)\n","\n","df_match = financeadvisor_embeddings\n","df_match[\"similarities\"] = df_match['embedding'].apply(lambda x: cosine_similarity(x, question_vector))\n","df_match = df_match.sort_values(\"similarities\", ascending=False).head(4)\n","\n","df_match['similarities']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HJO25Ek0v74g"},"outputs":[],"source":["episode[\"similarities\"]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aOCHjXALvdZd"},"outputs":[],"source":["context = []\n","for i, row in episode.iterrows():\n","  context.append(row['context'])\n","\n","context"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uO7sRnGqvicO"},"outputs":[],"source":["text = \"\\n\".join(context)\n","text"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"po9frEQpvpTR"},"outputs":[],"source":["prompt = f\"\"\"Answer the following question using only the context below. Answer in the style of Ben Carlson a financial advisor and podcaster. If you don't know the answer for certain, say I don't know.\n","\n","Context:\n","{context}\n","\n","Q: {question}\n","A:\"\"\"\n","\n","openai.Completion.create(\n","    prompt=prompt,\n","    temperature=1,\n","    max_tokens=500,\n","    top_p=1,\n","    frequency_penalty=0,\n","    presence_penalty=0,\n","    model=COMPLETIONS_MODEL\n",")[\"choices\"][0][\"text\"].strip(\" \\n\")"]},{"cell_type":"markdown","metadata":{"id":"9f68jtfnNqck"},"source":["### Use pgvector to store the generated embeddings within PostgreSQL\n","\n","- The `pgvector` extension introduces a new `vector` data type.\n","- **The new `vector` data type allows you to directly save a vector embedding (represented as a NumPy array) through a simple INSERT statement in PostgreSQL!**\n","\n",">⚠️ The following code snippet may run for a few minutes."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hZKe_9qeRdMH"},"outputs":[],"source":["# Store the generated vector embeddings in a PostgreSQL table.\n","# This code may run for a few minutes.\n","\n","import asyncio\n","import asyncpg\n","from google.cloud.sql.connector import Connector\n","import numpy as np\n","from pgvector.asyncpg import register_vector\n","\n","\n","async def main():\n","    loop = asyncio.get_running_loop()\n","    async with Connector(loop=loop) as connector:\n","        # Create connection to Cloud SQL database.\n","        conn: asyncpg.Connection = await connector.connect_async(\n","            f\"{project_id}:{region}:{instance_name}\",  # Cloud SQL instance connection name\n","            \"asyncpg\",\n","            user=f\"{database_user}\",\n","            password=f\"{database_password}\",\n","            db=f\"{database_name}\",\n","        )\n","\n","        await conn.execute(\"CREATE EXTENSION IF NOT EXISTS vector\")\n","        await register_vector(conn)\n","\n","        await conn.execute(\"DROP TABLE IF EXISTS financeadvisor_embeddings\")\n","        # Create the `financeadvisor_embeddings` table to store vector embeddings.\n","        await conn.execute(\n","            \"\"\"CREATE TABLE financeadvisor_embeddings(\n","                                contextid VARCHAR(1024) NOT NULL REFERENCES financeadvisor(contextid),\n","                                content TEXT,\n","                                embedding vector(768))\"\"\"\n","        )\n","\n","        # Store all the generated embeddings back into the database.\n","        for index, row in financeadvisor_embeddings.iterrows():\n","            await conn.execute(\n","                \"INSERT INTO financeadvisor_embeddings (contextid, content, embedding) VALUES ($1, $2, $3)\",\n","                row[\"contextid\"],\n","                row[\"content\"],\n","                np.array(row[\"embedding\"]),\n","            )\n","\n","        await conn.close()\n","\n","\n","# Run the SQL commands now.\n","await main()  # type: ignore"]},{"cell_type":"markdown","metadata":{"id":"Lm0dVJeInyfM"},"source":["### Demo: Finding similar toy products using pgvector cosine search operator\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_zRBR9YJoENp"},"outputs":[],"source":["# @markdown Enter a short description of the toy to search for within a specified price range:\n","toy = \"playing card games\"  # @param {type:\"string\"}\n","min_price = 25  # @param {type:\"integer\"}\n","max_price = 100  # @param {type:\"integer\"}\n","\n","# Quick input validations.\n","assert toy, \"⚠️ Please input a valid input search text\"\n","\n","from langchain.embeddings import VertexAIEmbeddings\n","from google.cloud import aiplatform\n","\n","aiplatform.init(project=f\"{project_id}\", location=f\"{region}\")\n","\n","embeddings_service = VertexAIEmbeddings()\n","qe = embeddings_service.embed_query([toy])\n","from pgvector.asyncpg import register_vector\n","import asyncio\n","import asyncpg\n","from google.cloud.sql.connector import Connector\n","\n","matches = []\n","\n","\n","async def main():\n","    loop = asyncio.get_running_loop()\n","    async with Connector(loop=loop) as connector:\n","        # Create connection to Cloud SQL database.\n","        conn: asyncpg.Connection = await connector.connect_async(\n","            f\"{project_id}:{region}:{instance_name}\",  # Cloud SQL instance connection name\n","            \"asyncpg\",\n","            user=f\"{database_user}\",\n","            password=f\"{database_password}\",\n","            db=f\"{database_name}\",\n","        )\n","\n","        await register_vector(conn)\n","        similarity_threshold = 0.1\n","        num_matches = 50\n","\n","        # Find similar products to the query using cosine similarity search\n","        # over all vector embeddings. This new feature is provided by `pgvector`.\n","        results = await conn.fetch(\n","            \"\"\"\n","                            WITH vector_matches AS (\n","                              SELECT contextid, 1 - (embedding <=> $1) AS similarity\n","                              FROM financeadvisor_embeddings\n","                              WHERE 1 - (embedding <=> $1) > $2\n","                              ORDER BY similarity DESC\n","                              LIMIT $3\n","                            )\n","                            SELECT product_name, list_price, description FROM products\n","                            WHERE contextid IN (SELECT contextid FROM vector_matches)\n","                            AND list_price >= $4 AND list_price <= $5\n","                            \"\"\",\n","            qe,\n","            similarity_threshold,\n","            num_matches,\n","            min_price,\n","            max_price,\n","        )\n","\n","        if len(results) == 0:\n","            raise Exception(\"Did not find any results. Adjust the query parameters.\")\n","\n","        for r in results:\n","            # Collect the description for all the matched similar toy products.\n","            matches.append(\n","                {\n","                    \"product_name\": r[\"product_name\"],\n","                    \"context\": r[\"context\"],\n","                    \"list_price\": round(r[\"list_price\"], 2),\n","                }\n","            )\n","\n","        await conn.close()\n","\n","\n","# Run the SQL commands now.\n","await main()  # type: ignore\n","\n","# Show the results for similar products that matched the user query.\n","matches = pd.DataFrame(matches)\n","matches.head(5)"]},{"cell_type":"markdown","metadata":{"id":"5z25qzj4HO69"},"source":["Checkpoint:\n","- We have extracted the semantic knowledge of the dataset and made it searchable through pgvector and PostgreSQL.\n","- The demo will show next how you can use this semantic knowledge to answer complex natural language queries using LLMs."]},{"cell_type":"markdown","metadata":{"id":"3nGqYKJgI4nJ"},"source":["## Level 2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oE5o40h-KMSi"},"outputs":[],"source":["episode['context'].iloc[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aKq3zRP1m0YB"},"outputs":[],"source":["from openai.embeddings_utils import get_embedding\n","\n","# get_embedding(episode.iloc[0]['context'], engine=EMBEDDINGS_MODEL)\n","\n","episode['embedding'] = episode['context'].apply(lambda row: get_embedding(row, engine=EMBEDDINGS_MODEL))\n","episode.to_csv('question_embeddings.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ioUdNyGSO4pv"},"outputs":[],"source":["episode['embedding'].iloc[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2eWxJKp7Pdxu"},"outputs":[],"source":["episode.iloc[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BULieJNUq7D4"},"outputs":[],"source":["from openai.embeddings_utils import cosine_similarity\n","\n","question = \"Should I buy a house with cash?\"\n","question_vector = get_embedding(question, engine=EMBEDDINGS_MODEL)\n","\n","episode[\"similarities\"] = episode['embedding'].apply(lambda x: cosine_similarity(x, question_vector))\n","episode = episode.sort_values(\"similarities\", ascending=False).head(4)\n","\n","episode"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lpB7j02HrbTr"},"outputs":[],"source":["episode.to_csv(\"sorted.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q3QTUcUPwhlQ"},"outputs":[],"source":["context = []\n","for i, row in episode.iterrows():\n","  context.append(row['context'])\n","\n","context"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QJpRCSODxmxp"},"outputs":[],"source":["text = \"\\n\".join(context)\n","text"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yQ5ha5FgxtsU"},"outputs":[],"source":["context = text\n","\n","context"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-BfERMoXOpC5"},"outputs":[],"source":["prompt = f\"\"\"Answer the following question using only the context below. Answer in the style of Ben Carlson a financial advisor and podcaster. If you don't know the answer for certain, say I don't know.\n","\n","Context:\n","{context}\n","\n","Q: {question}\n","A:\"\"\"\n","\n","openai.Completion.create(\n","    prompt=prompt,\n","    temperature=1,\n","    max_tokens=500,\n","    top_p=1,\n","    frequency_penalty=0,\n","    presence_penalty=0,\n","    model=COMPLETIONS_MODEL\n",")[\"choices\"][0][\"text\"].strip(\" \\n\")"]},{"cell_type":"markdown","metadata":{"id":"2vs34CUI32Wc"},"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1cVQNg2-zGQb7qZXFECG6kyq5yVIHyf5o","timestamp":1688505763331}],"toc_visible":true},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}